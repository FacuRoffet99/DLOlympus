{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gitlab setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = \n",
    "email = \n",
    "username = \n",
    "repo = \n",
    "id = \n",
    "branch = \n",
    "experiment =\n",
    "\n",
    "!git config --global user.email {email}\n",
    "!git config --global user.name {username}\n",
    "\n",
    "import os\n",
    "os.environ['MLFLOW_TRACKING_URI'] = f'https://gitlab.com/api/v4/projects/{id}/ml/mlflow'\n",
    "os.environ['MLFLOW_TRACKING_TOKEN'] = token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone -b {branch} https://oauth2:{token}@gitlab.com/{username}/{repo}.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from fastai.vision.all import *\n",
    "import albumentations\n",
    "from DLOlympus.training.transforms import AlbumentationsTransform\n",
    "from DLOlympus.training.utils import get_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "root = 'path_to_main_folder/'\n",
    "images_folder = root/'images/'\n",
    "save_path = root/\n",
    "other_paths = root/'declare_other_paths/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "\n",
    "h, w = 200, 200\n",
    "\n",
    "hyperparameters = {\n",
    "    'BS': 16,\n",
    "    'EPOCHS': 30,\n",
    "    'IMG_SIZE': (h, w),      # (height, width)\n",
    "    'WD': 0.15,\n",
    "    'TRANSFORMS': [\n",
    "        albumentations.HorizontalFlip(p=0.5),\n",
    "        albumentations.VerticalFlip(p=0.5),\n",
    "        albumentations.Rotate(p=0.5),\n",
    "        albumentations.Sharpen(p=0.5),\n",
    "        albumentations.ColorJitter(brightness=0.3, contrast=0.5, saturation=0.5, hue=0.0, p=0.5),\n",
    "        albumentations.RGBShift(p=0.5),\n",
    "        albumentations.GaussianBlur(p=0.5),\n",
    "        albumentations.GaussNoise(p=0.5),\n",
    "        albumentations.RandomSizedCrop((int(0.75*h),h), h, w, p=1.0)\n",
    "        ],\n",
    "    'ARCH': 'resnet50',\n",
    "    'ARCH_TYPE': 'torchvision',\n",
    "    'SEED': 18,\n",
    "}\n",
    "\n",
    "# Metrics and callbacks\n",
    "metrics = [accuracy, F1Score(average='macro')]\n",
    "callbacks = [SaveModelCallback(monitor='f1_score', with_opt=True), ShowGraphCallback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "\n",
    "def get_data():\n",
    "    image_files = \n",
    "    labels = \n",
    "    groups = \n",
    "    return image_files, labels, groups\n",
    "\n",
    "def create_df(image_files, labels, groups, n_splits=10, n_valid=2):\n",
    "    # Initiate dataframe\n",
    "    df = pd.DataFrame()\n",
    "    df['file_path'] = image_files\n",
    "    df['label'] = labels\n",
    "    df['groups'] = groups\n",
    "    df['fold'] = -1\n",
    "    # Make folds\n",
    "    cv = StratifiedGroupKFold(n_splits=n_splits)\n",
    "    for i, (train_idxs, valid_idxs) in enumerate(cv.split(image_files, labels, groups)):\n",
    "        df.loc[valid_idxs, ['fold']] = i\n",
    "    # Assign folds for validation\n",
    "    df['split'] = 'train'\n",
    "    for i in range (n_valid):\n",
    "        df.loc[df.fold == i, ['split']] = 'valid'\n",
    "    del df['fold']\n",
    "    df.split.value_counts()\n",
    "    # Add a binary column to the dataframe\n",
    "    df['is_valid'] = df.split == 'valid'\n",
    "    del df['split']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(hyperparameters['SEED'], True)\n",
    "\n",
    "# Datablock\n",
    "block = DataBlock(\n",
    "    blocks=(ImageBlock, CategoryBlock),\n",
    "    get_x=ColReader('file_path'),\n",
    "    get_y=ColReader('label'),\n",
    "    splitter=ColSplitter(col='is_valid'),\n",
    "    item_tfms=[\n",
    "        Resize(hyperparameters['IMG_SIZE'], method='squish'), \n",
    "        AlbumentationsTransform(albumentations.Compose(hyperparameters['TRANSFORMS']))])\n",
    "\n",
    "# Dataframe\n",
    "image_files, labels, groups = get_data()\n",
    "df = create_df(image_files, labels, groups)\n",
    "\n",
    "# Dataloaders\n",
    "dls = block.dataloaders(df, bs=hyperparameters['BS'], shuffle=True)\n",
    "dls.rng.seed(hyperparameters['SEED'])\n",
    "\n",
    "# Sanity check\n",
    "num_classes = dls.c\n",
    "classes = dls.vocab\n",
    "print('Number of clases: ', num_classes)\n",
    "print('Names of classes: ', classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show batch\n",
    "dls.train.show_batch(max_n=16, figsize=(10,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show transforms\n",
    "dls.train.show_batch(max_n=16, unique=True, figsize=(10,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learner\n",
    "learn = vision_learner(dls,\n",
    "                        get_model(hyperparameters),\n",
    "                        normalize=True,\n",
    "                        pretrained=True,\n",
    "                        opt_func=Adam,\n",
    "                        metrics=metrics,\n",
    "                        wd=hyperparameters['WD']).to_fp16()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find LR\n",
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set LR\n",
    "hyperparameters['LR'] = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "learn.fine_tune(hyperparameters['EPOCHS'], base_lr=hyperparameters['LR'], cbs=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results and logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.export(f'{save_path}/model.pkl')\n",
    "learn.save(f'{save_path}/model')\n",
    "\n",
    "from DLOlympus.training.plots import plot_confusion_matrix, plot_losses, plot_metrics\n",
    "_ = plot_losses(learn, save_path)\n",
    "_ = plot_metrics(learn, save_path)\n",
    "probs, ground_truths = learn.get_preds(ds_idx=1)        # DO NOT PREDICT BEFORE PLOTTING LOSSES AND METRICS\n",
    "predictions = np.argmax(probs, axis=1)\n",
    "_ = plot_confusion_matrix(ground_truths, predictions, learn.dls.vocab, save_path)\n",
    "\n",
    "from DLOlympus.training.tables import get_predictions_table\n",
    "train_table = get_predictions_table(learn, learn.dls.train)\n",
    "valid_table = get_predictions_table(learn, learn.dls.valid)\n",
    "train_table.to_csv(f'{save_path}train_table.csv', index=False)\n",
    "valid_table.to_csv(f'{save_path}valid_table.csv', index=False)\n",
    "\n",
    "from DLOlympus.training.utils import get_metrics\n",
    "results = get_metrics(learn, with_tta=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DLOlympus.training.mlflow import mlflow_log\n",
    "\n",
    "mlflow_log(save_path, hyperparameters, results, experiment)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multicare",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
